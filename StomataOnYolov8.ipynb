{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Essential Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ray/.local/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: ultralytics in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (8.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (1.26.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: hub-sdk>=0.0.2 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (0.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ray/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ray/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ray/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.2.140)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ray/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: torch in /home/ray/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchvision in /home/ray/.local/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: torchaudio in /home/ray/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/ray/.local/lib/python3.10/site-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ray/.local/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ray/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ray/.local/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ray/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ray/.local/lib/python3.10/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ray/.local/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ray/.local/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ray/.local/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ray/.local/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ray/.local/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ray/.local/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ray/.local/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ray/.local/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ray/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: numpy in /home/ray/.local/lib/python3.10/site-packages (from torchvision) (1.26.1)\n",
      "Requirement already satisfied: requests in /home/ray/.local/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ray/.local/lib/python3.10/site-packages (from requests->torchvision) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ray/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: utils in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install  tqdm\n",
    "!pip install ultralytics\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install utils\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "from IPython.display import Image  # for displaying images\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw ,ImageFont\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "font_path = os.path.join(cv2.__path__[0],'qt','fonts','DejaVuSans.ttf')\n",
    "random.seed(108)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Label On Image\n",
    "## Extract Info From Xml\n",
    "## change PASCAL VOC .xml to yolov5 .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ray/StomataYolov8\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the data from XML Annotation\n",
    "def extract_info_from_xml(xml_file):\n",
    "    root = ET.parse(xml_file).getroot()\n",
    "\n",
    "    # Initialise the info dict\n",
    "    info_dict = {}\n",
    "    info_dict['bboxes'] = []\n",
    "    \n",
    "    for elem in root:\n",
    "        # Get the file name\n",
    "        if elem.tag == \"filename\":\n",
    "            info_dict['filename'] = elem.text\n",
    "\n",
    "        # Get the image size\n",
    "        elif elem.tag == \"size\":\n",
    "            image_size = []\n",
    "            for subelem in elem:\n",
    "                image_size.append(int(subelem.text))\n",
    "\n",
    "            info_dict['image_size'] = tuple(image_size)\n",
    "\n",
    "        # Get details of the bounding box\n",
    "        elif elem.tag == \"object\":\n",
    "            bbox = {}\n",
    "            for subelem in elem:\n",
    "                if subelem.tag == \"name\":\n",
    "                    bbox[\"class\"] = subelem.text\n",
    "\n",
    "                elif subelem.tag == \"robndbox\":\n",
    "                    for subsubelem in subelem:\n",
    "                        bbox[subsubelem.tag] = int(float(subsubelem.text))\n",
    "            info_dict['bboxes'].append(bbox)\n",
    "\n",
    "    return info_dict\n",
    "\n",
    "\n",
    "#xml choose complete\n",
    "\n",
    "class_name_to_id_mapping = {\"complete\": 0,\n",
    "                \"incomplete\": 1,\n",
    "                           \"blurry.complete\": 2,\n",
    "                           \"blurry.incomplete\" :3 , #\n",
    "                           \"hair\":4} # human hair\n",
    "\n",
    "# change robndbox to yolov5 format\n",
    "def convert_to_yolov8(info_dict) :\n",
    "    print_buffer = []\n",
    "\n",
    "    # For each bounding box\n",
    "    for b in info_dict[\"bboxes\"]:\n",
    "        try:\n",
    "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
    "        except KeyError:\n",
    "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
    "\n",
    "        # robndbox format\n",
    "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
    "        b_center_x = int(b[\"cx\"])\n",
    "        b_center_y = int(b[\"cy\"])\n",
    "        b_width = int(b[\"w\"])\n",
    "        b_height = int(b[\"h\"])\n",
    "\n",
    "        # Normalise the co-ordinates by the dimensions of the image\n",
    "        image_w, image_h, image_c = info_dict[\"image_size\"]\n",
    "        b_center_x /= image_w\n",
    "        b_center_y /= image_h\n",
    "        b_width    /= image_w\n",
    "        b_height   /= image_h\n",
    "\n",
    "        #Write the bbox details to the file\n",
    "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
    "\n",
    "    # Name of the file which we have to save\n",
    "    save_file_name = os.path.join(\"./AllDataset\", info_dict[\"filename\"] + '.txt' )\n",
    "\n",
    "    # Save the annotation to disk\n",
    "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './AllDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ray/StomataYolov8/StomataOnYolov8.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Get the annotationse\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m annotations \u001b[39m=\u001b[39m [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m./AllDataset\u001b[39m\u001b[39m'\u001b[39m, x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39m./AllDataset\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mif\u001b[39;00m x[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxml\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m annotations\u001b[39m.\u001b[39msort()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#print(annotations)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Convert and save the annotations\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './AllDataset'"
     ]
    }
   ],
   "source": [
    "# Get the annotationse\n",
    "annotations = [os.path.join('./AllData', x) for x in os.listdir('./AllData') if x[-3:] == \"xml\"]\n",
    "\n",
    "\n",
    "annotations.sort()\n",
    "#print(annotations)\n",
    "# Convert and save the annotations\n",
    "for ann in tqdm(annotations):\n",
    "    info_dict = extract_info_from_xml(ann)\n",
    "    convert_to_yolov8(info_dict)\n",
    "    \n",
    "annotations = [os.path.join('./AllData', x) for x in os.listdir('./AllData') if x[-3:] == \"txt\"]\n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the annotations\n",
    "\n",
    "## Label the class on the image\n",
    "Just for a sanity check, let us now test some of these transformed annotations. We randomly load one of the annotations and plot boxes using the transformed annotations, and visually inspect it to see whether our code has worked as intended.\n",
    "\n",
    "Run the next cell multiple times. Every time, a random annotation is sampled.\n",
    "\n",
    "Use command mv ./T22/*_label.jpg ./T22Label  \n",
    "move label image to folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'annotations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ray/StomataYolov8/StomataOnYolov8.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mwith open(annotation_file, \"r\") as file:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m    annotation_list = file.read().split(\"\\n\")[:-1]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m    annotation_list = [x.split(\" \") for x in annotation_list]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m    annotation_list = [[float(y) for y in x ] for x in annotation_list]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m'''\u001b[39;00m    \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# use %cd T22Label to locate folder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# Plot the Bounding Box\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Polt all the Images Labels and annotations\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(annotations)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     annotation_file \u001b[39m=\u001b[39m annotations[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ray/StomataYolov8/StomataOnYolov8.ipynb#X11sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(annotation_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'annotations' is not defined"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "\n",
    "class_name_to_id_mapping = {\"complete\": 0,\n",
    "                \"incomplete\": 1,\n",
    "                           \"blurry.complete\": 2,\n",
    "                           \"blurry.incomplete\" :3 , \n",
    "                           \"hair\":4\n",
    "                           } # human hair\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "fnt = ImageFont.truetype(\"Pillow/Tests/fonts/FreeMono.ttf\", 40)\n",
    "\n",
    "\n",
    "\n",
    "def PlotAndSavebounding_box(image_name,image, annotation_list):\n",
    "    annotations = np.array(annotation_list)\n",
    "    w, h = image.size\n",
    "\n",
    "    plotted_image = ImageDraw.Draw(image)\n",
    "\n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
    "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h\n",
    "\n",
    "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
    "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
    "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
    "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
    "\n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        plotted_image.rectangle(((x0,y0), (x1,y1)),outline =\"red\", width = 3)\n",
    "        plotted_image.text((x0, y0-10), class_id_to_name_mapping[(int(obj_cls))] , fill = (255,0,255,255), font = fnt)\n",
    "    \n",
    "    # covert PIL image to cv2 image\n",
    "    open_cv_image = np.array(image)\n",
    "\n",
    "    # Convert RGB to BGR\n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "\n",
    "    print(type(image))\n",
    "\n",
    "\n",
    "    image_name = image_name.replace(\".jpg\", \"_label.jpg\")\n",
    "    \n",
    "    cv2.imwrite( image_name , open_cv_image, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "\n",
    "    #plt.imshow(np.array(image))\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# Get any random annotation file\n",
    "#annotation_file = annotations[0]\n",
    "\n",
    "'''\n",
    "with open(annotation_file, \"r\") as file:\n",
    "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "'''    \n",
    "\n",
    "\n",
    "# use %cd T22Label to locate folder\n",
    "\n",
    "# Plot the Bounding Box\n",
    "# Polt all the Images Labels and annotations\n",
    "for i in range(0,len(annotations)):\n",
    "\n",
    "    annotation_file = annotations[i]\n",
    "\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "        annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "        annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "\n",
    "    #Get the corresponding image file\n",
    "    image_file = annotation_file.replace(\"txt\", \"jpg\")\n",
    "    \n",
    "    assert os.path.exists(image_file)\n",
    "\n",
    "    #Load the image\n",
    "\n",
    "    image = Image.open(image_file)\n",
    "    PlotAndSavebounding_box(image_file,image, annotation_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count all class of images\n",
    "export the csv file of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotations = [os.path.join('/home/ray/datasets/T32/labels/train', x) for x in os.listdir('/home/ray/datasets/T32/labels/train') if x[-3:] == \"txt\"]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class_name_to_id_mapping = {\"complete\": 0,\n",
    "                \"incomplete\": 1,\n",
    "                           \"blurry.complete\": 2,\n",
    "                           \"blurry.incomplete\" :3 , \n",
    "                           \"hair\":4\n",
    "                           } # human hair\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def CountAndSaveInstance(dic, annotation_list) :\n",
    "    annotations = np.array(annotation_list)\n",
    "    \n",
    "\n",
    "    \n",
    "    transformed_annotations = np.copy(annotations)\n",
    "    \n",
    "    for ann in transformed_annotations:\n",
    "        obj_cls, x0, y0, x1, y1 = ann\n",
    "        dic[\"count\"][int(obj_cls)] += 1\n",
    "    \n",
    "    \n",
    "# Set original  \n",
    "dic = { \"class\" : class_name_to_id_mapping.keys() , \"count\" : [0,0,0,0,0]}\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(annotations)):\n",
    "\n",
    "    annotation_file = annotations[i]\n",
    "\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        annotation_list = file.read().split(\"\\n\")[:-1]\n",
    "        annotation_list = [x.split(\" \") for x in annotation_list]\n",
    "        annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
    "\n",
    "    #\n",
    "    CountAndSaveInstance(dic,annotation_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complete</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incomplete</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blurry.complete</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blurry.incomplete</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hair</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               class  count\n",
       "0           complete    862\n",
       "1         incomplete     62\n",
       "2    blurry.complete    587\n",
       "3  blurry.incomplete    120\n",
       "4               hair    874"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_df = pd.DataFrame(dic)\n",
    "dic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_df.to_csv('T22Count.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Image and Annotation\n",
    "###   Split to train datasets and Test data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and annotations\n",
    "images = [os.path.join('./T32', x) for x in os.listdir('./T32') if x[-3:] == 'jpg' ]\n",
    "annotations = [os.path.join('./T32', x) for x in os.listdir('./T32') if x[-3:] == \"txt\"]\n",
    "\n",
    "images.sort()\n",
    "annotations.sort()\n",
    "\n",
    "# Split the dataset into train-valid-test splits\n",
    "train_images, val_images, train_annotations, val_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
    "val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the folders to keep the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./T32/images ./T32/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./T32/images/train ./T32/images/val ./T32/images/test  ./T32/labels/train  ./T32/labels/val  ./T32/labels/test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move the files to their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility function to move images\n",
    "def move_files_to_folder(list_of_files, destination_folder):\n",
    "    for f in list_of_files:\n",
    "        try:\n",
    "            shutil.move(f, destination_folder)\n",
    "        except:\n",
    "            print(f)\n",
    "            assert False\n",
    "\n",
    "\n",
    "# Move the splits into their folders\n",
    "move_files_to_folder(train_images, './T32/images/train')\n",
    "move_files_to_folder(val_images, './T32/images/val/')\n",
    "move_files_to_folder(test_images, './T32/images/test/')\n",
    "move_files_to_folder(train_annotations, './T32/labels/train/')\n",
    "move_files_to_folder(val_annotations, './T32/labels/val/')\n",
    "move_files_to_folder(test_annotations, './T32/labels/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a new file called road_sign_data.yaml and place it in the yolov5/data folder. Then populate it with the following.\n",
    "\n",
    "train : ./T22/images/train/\n",
    "val : ./T22/images/val/\n",
    "test : ./T22/images/test/\n",
    "\n",
    "\n",
    "##### number of classes\n",
    "nc: 5\n",
    "\n",
    "##### class names\n",
    "names : [\"complete\", \"incomplete\",\"blurry.complete\",\"blurry.incomplete\" , \"hair\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Yolov8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (8.0.232)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.1.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (1.26.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: psutil in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (2.1.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/ray/.local/lib/python3.10/site-packages (from ultralytics) (0.13.0)\n",
      "Collecting hub-sdk>=0.0.2 (from ultralytics)\n",
      "  Downloading hub_sdk-0.0.2-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ray/.local/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ray/.local/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ray/.local/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: filelock in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/ray/.local/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ray/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.2.140)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ray/anaconda3/envs/Yolov8Stomata/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ray/.local/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.1.0-py3-none-any.whl (699 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.2/699.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hub_sdk-0.0.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: hub-sdk, ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.0.232\n",
      "    Uninstalling ultralytics-8.0.232:\n",
      "      Successfully uninstalled ultralytics-8.0.232\n",
      "Successfully installed hub-sdk-0.0.2 ultralytics-8.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m-obb.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.238 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.232 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 7937MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/ray/runs/detect/T22+T32Train/weights/best.pt, data=data_T22T32.yaml, epochs=250, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/home/ray/runs/detect/train7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
      "Model summary: 225 layers, 11137535 parameters, 11137519 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ray/datasets/T22+T32/labels/train.cache... 146 images, 0 backgrounds, 0 corrupt: 100%|██████████| 146/146 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ray/datasets/T22+T32/labels/val.cache... 17 images, 0 backgrounds, 0 corrupt: 100%|██████████| 17/17 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/ray/runs/detect/train7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "250 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/250      5.04G     0.6861     0.3726     0.8243        214        640: 100%|██████████| 10/10 [00:02<00:00,  3.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.798      0.753      0.805      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/250       5.4G     0.7293     0.3973     0.8344        127        640: 100%|██████████| 10/10 [00:01<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.745      0.779      0.786      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/250      4.92G     0.6938     0.3771     0.8259        215        640: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.763      0.779      0.798      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/250      5.24G      0.707      0.388     0.8279        206        640: 100%|██████████| 10/10 [00:01<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.801      0.744      0.807      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/250      4.86G      0.753     0.4192     0.8354        138        640: 100%|██████████| 10/10 [00:01<00:00,  5.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.734      0.787       0.82      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/250      5.16G     0.7288     0.4095     0.8296        110        640: 100%|██████████| 10/10 [00:01<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.808      0.723      0.816      0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/250         5G     0.7449     0.4165     0.8321        170        640: 100%|██████████| 10/10 [00:01<00:00,  5.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.756      0.786      0.791      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/250      5.53G     0.7757     0.4399     0.8394        122        640: 100%|██████████| 10/10 [00:01<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.763      0.761      0.781       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/250      5.07G     0.7411     0.4088     0.8308        152        640: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.727      0.781      0.793      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/250      5.18G     0.7401     0.4058     0.8317        174        640: 100%|██████████| 10/10 [00:01<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.755      0.731      0.776      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/250      5.11G     0.7617     0.4284     0.8385         90        640: 100%|██████████| 10/10 [00:01<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829        0.8      0.701      0.793      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/250      5.21G     0.7931     0.4481     0.8485        101        640: 100%|██████████| 10/10 [00:01<00:00,  5.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.713      0.765      0.785      0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/250       4.6G     0.7775     0.4302     0.8375        147        640: 100%|██████████| 10/10 [00:01<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.777      0.746      0.778      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/250      5.31G     0.7702     0.4402     0.8415        106        640: 100%|██████████| 10/10 [00:01<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.758      0.776      0.797      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/250      5.76G     0.7382      0.419     0.8438        100        640: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.779       0.76      0.787      0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/250      4.88G     0.8024     0.4674     0.8279        306        640: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.769      0.777      0.799       0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/250      5.48G     0.8016     0.4372     0.8519        134        640: 100%|██████████| 10/10 [00:01<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.789       0.76       0.78      0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/250      5.64G     0.8149     0.4531     0.8426        196        640: 100%|██████████| 10/10 [00:01<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.798      0.762      0.786      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/250      5.43G     0.7838     0.4332     0.8387        194        640: 100%|██████████| 10/10 [00:01<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.772      0.739       0.79      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/250      5.44G     0.7624     0.4236     0.8456        102        640: 100%|██████████| 10/10 [00:01<00:00,  5.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.717      0.816      0.784      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/250      4.61G     0.7826     0.4251     0.8481        147        640: 100%|██████████| 10/10 [00:01<00:00,  5.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.765      0.745      0.767       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/250      6.01G     0.7952     0.4247     0.8435        217        640: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.735      0.777      0.775      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/250      4.84G     0.8129     0.4389     0.8493        161        640: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.755      0.782      0.779      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/250      4.55G     0.8234     0.4426     0.8393        194        640: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.787      0.728      0.766      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/250      5.42G       0.76      0.417     0.8329        139        640: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.795      0.704      0.784      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/250      5.42G      0.808     0.4434      0.845        240        640: 100%|██████████| 10/10 [00:01<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.725      0.784      0.793      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/250      6.17G      0.776      0.424      0.841        143        640: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.757      0.735      0.782      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/250      5.75G      0.767     0.4211     0.8401        121        640: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829       0.78      0.742      0.794      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/250      4.72G     0.7556     0.4101      0.834        209        640: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829       0.81      0.721      0.795      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/250       5.6G     0.7352      0.408      0.834        117        640: 100%|██████████| 10/10 [00:01<00:00,  5.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.775      0.761      0.782      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/250      4.58G     0.7736     0.4185     0.8392         93        640: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.733      0.779      0.783      0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/250      5.16G      0.781     0.4316     0.8423        106        640: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.757      0.772      0.805      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/250      5.66G     0.7754     0.4168     0.8403        117        640: 100%|██████████| 10/10 [00:01<00:00,  5.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.764      0.768      0.805      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/250      5.49G     0.7484     0.4088     0.8362        197        640: 100%|██████████| 10/10 [00:01<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.784      0.757      0.814      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/250      4.55G     0.7382     0.4116     0.8358        110        640: 100%|██████████| 10/10 [00:01<00:00,  6.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.754      0.795      0.801      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/250      4.99G     0.7327     0.4193     0.8368        130        640: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.746      0.764      0.781      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/250      5.51G      0.761     0.4095     0.8351        153        640: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.762      0.745      0.775      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/250      5.33G     0.8048     0.4485     0.8367        186        640: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.746      0.713      0.764      0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/250      4.88G     0.8028      0.436     0.8475        188        640: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.726      0.755      0.783      0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/250      5.59G     0.7932     0.4406     0.8493        114        640: 100%|██████████| 10/10 [00:01<00:00,  5.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.818      0.714      0.809      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/250      5.08G     0.8059     0.4399     0.8497        128        640: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829       0.75      0.751      0.781      0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/250      5.02G     0.8109     0.4352     0.8495        113        640: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.724      0.763      0.777      0.548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/250      5.31G     0.8465     0.4595     0.8466        113        640: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829       0.69      0.794      0.773      0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/250      5.69G     0.7988     0.4442     0.8433        118        640: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.777      0.708      0.797      0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/250         6G     0.8063     0.4455     0.8446         61        640: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.792      0.717      0.806      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/250      5.78G     0.7996     0.4331       0.84        193        640: 100%|██████████| 10/10 [00:01<00:00,  5.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829       0.74      0.749      0.786       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/250       5.6G     0.7592      0.414     0.8345        138        640: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.787      0.701      0.784      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/250       5.1G     0.7608     0.4104     0.8387        187        640: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.765      0.732      0.773      0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/250      5.11G     0.7318     0.3989     0.8331        112        640: 100%|██████████| 10/10 [00:01<00:00,  5.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.795      0.718      0.775      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/250      5.08G     0.7132     0.3983     0.8302        135        640: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.721      0.783      0.796      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/250       5.7G     0.7466     0.4117     0.8412        121        640: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.736      0.789      0.803      0.586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/250      5.74G     0.7246      0.401     0.8293        187        640: 100%|██████████| 10/10 [00:01<00:00,  5.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.857      0.706      0.793      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/250      5.46G     0.7296     0.4122     0.8345         66        640: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.837      0.732      0.807      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/250      5.55G      0.733     0.3943     0.8298        226        640: 100%|██████████| 10/10 [00:01<00:00,  5.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.756      0.808       0.79      0.564\n",
      "Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 4, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "54 epochs completed in 0.039 hours.\n",
      "Optimizer stripped from /home/ray/runs/detect/train7/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /home/ray/runs/detect/train7/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /home/ray/runs/detect/train7/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.232 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 7937MiB)\n",
      "Model summary (fused): 168 layers, 11127519 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.802      0.744      0.806      0.596\n",
      "              complete         17        212      0.794      0.856      0.831       0.69\n",
      "            incomplete         17         32      0.781      0.688      0.749      0.577\n",
      "       blurry.complete         17        198      0.844      0.773      0.807      0.646\n",
      "     blurry.incomplete         17         24      0.669      0.667      0.765      0.573\n",
      "                  hair         17        363      0.921      0.736      0.879      0.494\n",
      "Speed: 0.1ms preprocess, 1.9ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ray/runs/detect/train7\u001b[0m\n",
      "Ultralytics YOLOv8.0.232 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 7937MiB)\n",
      "Model summary (fused): 168 layers, 11127519 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ray/datasets/T22+T32/labels/val.cache... 17 images, 0 backgrounds, 0 corrupt: 100%|██████████| 17/17 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.801      0.743      0.809      0.597\n",
      "              complete         17        212      0.794      0.855      0.831      0.694\n",
      "            incomplete         17         32      0.781      0.688       0.77       0.57\n",
      "       blurry.complete         17        198      0.843      0.773      0.806      0.645\n",
      "     blurry.incomplete         17         24      0.669      0.667      0.765      0.581\n",
      "                  hair         17        363      0.917      0.733      0.873      0.495\n",
      "Speed: 0.2ms preprocess, 4.1ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ray/runs/detect/train73\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"/home/ray/runs/detect/T22+T32Train/weights/best.pt\")  # load an official model\n",
    "results = model.train(data=\"data_T22T32.yaml\", epochs=250)\n",
    "# Validate the model\n",
    "results = model.val(data=\"data_T22T32.yaml\")  # no arguments needed, dataset and settings remembered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.232 🚀 Python-3.10.13 torch-2.1.0+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Ti, 7937MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 168 layers, 11127519 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ray/datasets/T22+T32/labels/val.cache... 17 images, 0 backgrounds, 0 corrupt: 100%|██████████| 17/17 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17        829      0.775      0.792       0.82      0.603\n",
      "              complete         17        212      0.768      0.882      0.801      0.687\n",
      "            incomplete         17         32      0.753      0.688      0.835      0.614\n",
      "       blurry.complete         17        198      0.811      0.773      0.774      0.643\n",
      "     blurry.incomplete         17         24      0.674      0.792      0.794      0.561\n",
      "                  hair         17        363       0.87      0.826      0.895       0.51\n",
      "Speed: 0.2ms preprocess, 7.6ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/ray/runs/detect/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"/home/ray/runs/detect/T22+T32Train/weights/best.pt\")  # load an official model \n",
    "results = model.val(data=\"data_T22T32.yaml\")  # no arguments needed, dataset and settings remembered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P14_G35_4.jpg: 480x640 26 completes, 10 blurry.completes, 1 blurry.incomplete, 48 hairs, 79.5ms\n",
      "image 2/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P14_G35_5.jpg: 480x640 34 completes, 1 incomplete, 5 blurry.completes, 20 hairs, 3.5ms\n",
      "image 3/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P18_G13_4.jpg: 480x640 21 completes, 18 blurry.completes, 66 hairs, 4.1ms\n",
      "image 4/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P18_G13_7.jpg: 480x640 25 completes, 19 blurry.completes, 2 blurry.incompletes, 29 hairs, 4.0ms\n",
      "image 5/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P19_G49_3.jpg: 480x640 15 completes, 11 blurry.completes, 31 hairs, 3.8ms\n",
      "image 6/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P19_G49_6.jpg: 480x640 28 completes, 2 incompletes, 2 blurry.completes, 7 hairs, 3.4ms\n",
      "image 7/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P21_G54_1.jpg: 480x640 25 completes, 14 blurry.completes, 4 blurry.incompletes, 53 hairs, 3.8ms\n",
      "image 8/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P21_G54_5.jpg: 480x640 24 completes, 14 blurry.completes, 7 blurry.incompletes, 17 hairs, 3.8ms\n",
      "image 9/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P23_G29_4.jpg: 480x640 17 completes, 6 blurry.completes, 40 hairs, 3.8ms\n",
      "image 10/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P23_G29_7.jpg: 480x640 16 completes, 14 blurry.completes, 11 hairs, 3.4ms\n",
      "image 11/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P24_G44_2.jpg: 480x640 22 completes, 14 blurry.completes, 6 hairs, 4.2ms\n",
      "image 12/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P24_G44_7.jpg: 480x640 31 completes, 11 blurry.completes, 16 hairs, 3.4ms\n",
      "image 13/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P27_G48_2.jpg: 480x640 25 completes, 2 blurry.completes, 39 hairs, 4.0ms\n",
      "image 14/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P27_G48_8.jpg: 480x640 45 completes, 3 incompletes, 13 hairs, 3.4ms\n",
      "image 15/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P28_G60_1.jpg: 480x640 23 completes, 13 blurry.completes, 29 hairs, 4.2ms\n",
      "image 16/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P28_G60_8.jpg: 480x640 21 completes, 25 blurry.completes, 7 hairs, 3.4ms\n",
      "image 17/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P31_G67_4.jpg: 480x640 27 completes, 3 blurry.completes, 38 hairs, 3.4ms\n",
      "image 18/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P31_G67_6.jpg: 480x640 29 completes, 8 blurry.completes, 4 blurry.incompletes, 11 hairs, 3.8ms\n",
      "image 19/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P35_G100_1.jpg: 480x640 18 completes, 2 blurry.completes, 31 hairs, 3.4ms\n",
      "image 20/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P35_G100_7.jpg: 480x640 27 completes, 17 blurry.completes, 9 hairs, 3.6ms\n",
      "image 21/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P37_G16_4.jpg: 480x640 28 completes, 5 blurry.completes, 61 hairs, 3.4ms\n",
      "image 22/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P37_G16_7.jpg: 480x640 33 completes, 12 blurry.completes, 39 hairs, 4.4ms\n",
      "image 23/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P38_G50_1.jpg: 480x640 27 completes, 1 blurry.complete, 40 hairs, 3.5ms\n",
      "image 24/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P38_G50_5.jpg: 480x640 18 completes, 11 blurry.completes, 29 hairs, 4.8ms\n",
      "image 25/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P39_G99_3.jpg: 480x640 21 completes, 4 blurry.completes, 33 hairs, 3.4ms\n",
      "image 26/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P39_G99_6.jpg: 480x640 22 completes, 6 blurry.completes, 6 hairs, 3.4ms\n",
      "image 27/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P44_G83_1.jpg: 480x640 10 completes, 22 blurry.completes, 26 hairs, 3.4ms\n",
      "image 28/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P44_G83_7.jpg: 480x640 9 completes, 34 blurry.completes, 3 hairs, 3.4ms\n",
      "image 29/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P48_G61_1.jpg: 480x640 11 completes, 14 blurry.completes, 3 blurry.incompletes, 32 hairs, 4.3ms\n",
      "image 30/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P48_G61_5.jpg: 480x640 34 completes, 6 blurry.completes, 18 hairs, 3.6ms\n",
      "image 31/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P49_G105_3.jpg: 480x640 15 completes, 1 incomplete, 22 blurry.completes, 32 hairs, 3.8ms\n",
      "image 32/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P49_G105_7.jpg: 480x640 27 completes, 2 blurry.completes, 26 hairs, 3.4ms\n",
      "image 33/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P50_G26_4.jpg: 480x640 18 completes, 9 blurry.completes, 45 hairs, 4.0ms\n",
      "image 34/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P50_G26_7.jpg: 480x640 24 completes, 8 blurry.completes, 18 hairs, 3.5ms\n",
      "image 35/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P51_G87_2.jpg: 480x640 24 completes, 7 blurry.completes, 33 hairs, 4.4ms\n",
      "image 36/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P51_G87_7.jpg: 480x640 35 completes, 10 blurry.completes, 15 hairs, 3.6ms\n",
      "image 37/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P54_G103_3.jpg: 480x640 17 completes, 6 blurry.completes, 3 hairs, 3.4ms\n",
      "image 38/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P54_G103_7.jpg: 480x640 21 completes, 1 incomplete, 11 blurry.completes, 2 blurry.incompletes, 16 hairs, 3.4ms\n",
      "image 39/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P55_G55_4.jpg: 480x640 18 completes, 8 blurry.completes, 38 hairs, 3.8ms\n",
      "image 40/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P55_G55_5.jpg: 480x640 33 completes, 8 hairs, 3.4ms\n",
      "image 41/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P56_G12_3.jpg: 480x640 19 completes, 1 blurry.complete, 33 hairs, 3.8ms\n",
      "image 42/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P56_G12_7.jpg: 480x640 21 completes, 4 blurry.completes, 6 hairs, 3.4ms\n",
      "image 43/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P58_G88_3.jpg: 480x640 9 completes, 17 blurry.completes, 20 hairs, 3.8ms\n",
      "image 44/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P58_G88_5.jpg: 480x640 19 completes, 13 blurry.completes, 18 hairs, 3.4ms\n",
      "image 45/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P59_G47_3.jpg: 480x640 12 completes, 10 blurry.completes, 37 hairs, 3.4ms\n",
      "image 46/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P59_G47_6.jpg: 480x640 18 completes, 13 blurry.completes, 1 blurry.incomplete, 21 hairs, 4.5ms\n",
      "image 47/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P62_G66_4.jpg: 480x640 9 completes, 13 blurry.completes, 32 hairs, 3.4ms\n",
      "image 48/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P62_G66_6.jpg: 480x640 14 completes, 22 blurry.completes, 18 hairs, 3.6ms\n",
      "image 49/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P63_G18_4.jpg: 480x640 11 completes, 11 blurry.completes, 29 hairs, 3.6ms\n",
      "image 50/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P63_G18_6.jpg: 480x640 21 completes, 10 blurry.completes, 22 hairs, 3.4ms\n",
      "image 51/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P64_G31_2.jpg: 480x640 8 completes, 24 blurry.completes, 32 hairs, 3.3ms\n",
      "image 52/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P64_G31_6.jpg: 480x640 29 completes, 10 blurry.completes, 11 hairs, 3.7ms\n",
      "image 53/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P65_G80_1.jpg: 480x640 24 completes, 2 blurry.completes, 30 hairs, 3.9ms\n",
      "image 54/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P65_G80_7.jpg: 480x640 41 completes, 2 incompletes, 2 blurry.completes, 30 hairs, 3.6ms\n",
      "image 55/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P66_G97_3.jpg: 480x640 21 completes, 8 blurry.completes, 6 hairs, 3.4ms\n",
      "image 56/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P66_G97_5.jpg: 480x640 34 completes, 1 hair, 3.6ms\n",
      "image 57/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P69_G92_1.jpg: 480x640 16 completes, 12 blurry.completes, 29 hairs, 3.4ms\n",
      "image 58/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P69_G92_6.jpg: 480x640 4 completes, 29 blurry.completes, 11 hairs, 3.6ms\n",
      "image 59/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P70_G90_2.jpg: 480x640 18 completes, 2 blurry.completes, 21 hairs, 3.8ms\n",
      "image 60/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R1_P70_G90_6.jpg: 480x640 13 completes, 10 blurry.completes, 8 hairs, 3.6ms\n",
      "image 61/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P101_G225_3.jpg: 480x640 13 completes, 13 blurry.completes, 6 hairs, 3.4ms\n",
      "image 62/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P101_G225_8.jpg: 480x640 13 completes, 25 blurry.completes, 5 blurry.incompletes, 9 hairs, 3.4ms\n",
      "image 63/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P102_G201_1.jpg: 480x640 20 completes, 14 blurry.completes, 51 hairs, 3.5ms\n",
      "image 64/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P102_G201_7.jpg: 480x640 11 completes, 33 blurry.completes, 1 blurry.incomplete, 26 hairs, 3.4ms\n",
      "image 65/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P103_G212_1.jpg: 480x640 10 completes, 13 blurry.completes, 37 hairs, 3.8ms\n",
      "image 66/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P103_G212_7.jpg: 480x640 23 completes, 26 blurry.completes, 25 hairs, 3.6ms\n",
      "image 67/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P107_G118_1.jpg: 480x640 7 completes, 14 blurry.completes, 6 blurry.incompletes, 41 hairs, 3.5ms\n",
      "image 68/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P107_G118_8.jpg: 480x640 11 completes, 27 blurry.completes, 1 blurry.incomplete, 28 hairs, 3.6ms\n",
      "image 69/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P108_G134_2.jpg: 480x640 13 completes, 19 blurry.completes, 36 hairs, 3.3ms\n",
      "image 70/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P108_G134_5.jpg: 480x640 3 completes, 21 blurry.completes, 20 hairs, 3.4ms\n",
      "image 71/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P109_G161_3.jpg: 480x640 23 completes, 5 blurry.completes, 44 hairs, 4.4ms\n",
      "image 72/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P109_G161_6.jpg: 480x640 17 completes, 14 blurry.completes, 21 hairs, 3.4ms\n",
      "image 73/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P115_G119_3.jpg: 480x640 11 completes, 21 blurry.completes, 2 blurry.incompletes, 9 hairs, 3.4ms\n",
      "image 74/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P115_G119_7.jpg: 480x640 28 completes, 18 blurry.completes, 33 hairs, 4.3ms\n",
      "image 75/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P73_G171_1.jpg: 480x640 14 completes, 2 blurry.completes, 42 hairs, 3.4ms\n",
      "image 76/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P73_G171_8.jpg: 480x640 22 completes, 2 blurry.completes, 12 hairs, 4.0ms\n",
      "image 77/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P78_G173_4.jpg: 480x640 8 completes, 18 blurry.completes, 17 hairs, 3.4ms\n",
      "image 78/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P78_G173_8.jpg: 480x640 22 completes, 18 blurry.completes, 13 hairs, 3.7ms\n",
      "image 79/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P79_G209_4.jpg: 480x640 33 completes, 1 blurry.complete, 20 hairs, 3.6ms\n",
      "image 80/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P79_G209_6.jpg: 480x640 24 completes, 8 blurry.completes, 20 hairs, 3.6ms\n",
      "image 81/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P81_G108_4.jpg: 480x640 19 completes, 10 blurry.completes, 39 hairs, 3.7ms\n",
      "image 82/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P81_G108_6.jpg: 480x640 14 completes, 23 blurry.completes, 30 hairs, 4.1ms\n",
      "image 83/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P83_G199_3.jpg: 480x640 18 completes, 1 incomplete, 26 blurry.completes, 65 hairs, 4.1ms\n",
      "image 84/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P83_G199_6.jpg: 480x640 16 completes, 17 blurry.completes, 22 hairs, 3.4ms\n",
      "image 85/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P86_G190_3.jpg: 480x640 18 completes, 7 blurry.completes, 2 hairs, 3.7ms\n",
      "image 86/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P86_G190_5.jpg: 480x640 25 completes, 6 blurry.completes, 12 hairs, 3.4ms\n",
      "image 87/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P91_G166_1.jpg: 480x640 13 completes, 24 blurry.completes, 54 hairs, 3.4ms\n",
      "image 88/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P91_G166_8.jpg: 480x640 13 completes, 34 blurry.completes, 38 hairs, 4.1ms\n",
      "image 89/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P93_G213_2.jpg: 480x640 23 completes, 5 blurry.completes, 28 hairs, 3.4ms\n",
      "image 90/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P93_G213_7.jpg: 480x640 27 completes, 11 blurry.completes, 14 hairs, 3.4ms\n",
      "image 91/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P94_G176_2.jpg: 480x640 23 completes, 9 blurry.completes, 12 hairs, 4.0ms\n",
      "image 92/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P94_G176_8.jpg: 480x640 23 completes, 17 blurry.completes, 12 hairs, 3.4ms\n",
      "image 93/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P95_G178_1.jpg: 480x640 19 completes, 11 blurry.completes, 34 hairs, 3.4ms\n",
      "image 94/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P95_G178_8.jpg: 480x640 30 completes, 8 blurry.completes, 15 hairs, 3.6ms\n",
      "image 95/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P97_G203_4.jpg: 480x640 35 completes, 1 blurry.complete, 2 hairs, 3.4ms\n",
      "image 96/166 /home/ray/Downloads/Stomata/T22+T32/32TL600_W1_GC1_R2_P97_G203_6.jpg: 480x640 23 completes, 10 blurry.completes, 9 hairs, 3.4ms\n",
      "image 97/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P230_g190_2.jpg: 480x640 14 completes, 8 blurry.completes, 1 hair, 4.6ms\n",
      "image 98/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P230_g190_7.jpg: 480x640 18 completes, 15 blurry.completes, 2 hairs, 4.4ms\n",
      "image 99/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P231_g136_3.jpg: 480x640 5 completes, 8 blurry.completes, 12 hairs, 3.4ms\n",
      "image 100/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P231_g136_8.jpg: 480x640 11 completes, 14 blurry.completes, 5 hairs, 3.4ms\n",
      "image 101/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P234_g176_4.jpg: 480x640 9 completes, 12 blurry.completes, 16 hairs, 3.4ms\n",
      "image 102/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P234_g176_5.jpg: 480x640 7 completes, 18 blurry.completes, 2 hairs, 3.4ms\n",
      "image 103/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P236_g222_4.jpg: 480x640 14 completes, 10 blurry.completes, 3.5ms\n",
      "image 104/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P236_g222_5.jpg: 480x640 22 completes, 12 blurry.completes, 3.7ms\n",
      "image 105/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P239_g126_1.jpg: 480x640 13 completes, 7 blurry.completes, 3.4ms\n",
      "image 106/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P239_g126_7.jpg: 480x640 5 completes, 14 blurry.completes, 5 hairs, 3.4ms\n",
      "image 107/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P240_g111_1.jpg: 480x640 9 completes, 1 blurry.complete, 20 hairs, 3.5ms\n",
      "image 108/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P240_g111_8.jpg: 480x640 24 completes, 13 blurry.completes, 19 hairs, 3.8ms\n",
      "image 109/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P242_g178_2.jpg: 480x640 5 completes, 9 blurry.completes, 27 hairs, 3.4ms\n",
      "image 110/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P242_g178_6.jpg: 480x640 16 completes, 19 blurry.completes, 3 hairs, 3.6ms\n",
      "image 111/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P251_g194_3.jpg: 480x640 14 completes, 1 incomplete, 5 blurry.completes, 1 blurry.incomplete, 14 hairs, 3.9ms\n",
      "image 112/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P251_g194_6.jpg: 480x640 18 completes, 17 blurry.completes, 2 blurry.incompletes, 3 hairs, 3.8ms\n",
      "image 113/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P254_g108_3.jpg: 480x640 12 completes, 12 blurry.completes, 44 hairs, 3.4ms\n",
      "image 114/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P254_g108_6.jpg: 480x640 26 completes, 12 blurry.completes, 8 hairs, 4.2ms\n",
      "image 115/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P256_g119_2.jpg: 480x640 18 completes, 8 blurry.completes, 29 hairs, 3.4ms\n",
      "image 116/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P256_g119_5.jpg: 480x640 20 completes, 7 blurry.completes, 7 hairs, 3.4ms\n",
      "image 117/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P257_g171_3.jpg: 480x640 18 completes, 2 blurry.completes, 26 hairs, 3.8ms\n",
      "image 118/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P257_g171_7.jpg: 480x640 28 completes, 12 blurry.completes, 5 hairs, 3.6ms\n",
      "image 119/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P258_g150_4.jpg: 480x640 19 completes, 5 blurry.completes, 28 hairs, 4.5ms\n",
      "image 120/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P258_g150_5.jpg: 480x640 13 completes, 11 blurry.completes, 9 hairs, 4.4ms\n",
      "image 121/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P259_g212_2.jpg: 480x640 13 completes, 1 blurry.complete, 21 hairs, 4.1ms\n",
      "image 122/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_A4_R4_P259_g212_5.jpg: 480x640 12 completes, 8 blurry.completes, 6 blurry.incompletes, 1 hair, 3.4ms\n",
      "image 123/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P100_g60_4.jpg: 480x640 12 completes, 13 blurry.completes, 3 hairs, 3.4ms\n",
      "image 124/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P100_g60_5.jpg: 480x640 14 completes, 9 blurry.completes, 12 hairs, 3.8ms\n",
      "image 125/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P101_g49_2.jpg: 480x640 9 completes, 7 blurry.completes, 23 hairs, 3.5ms\n",
      "image 126/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P101_g49_5.jpg: 480x640 3 completes, 17 blurry.completes, 4 hairs, 4.4ms\n",
      "image 127/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P102_g97_4.jpg: 480x640 21 blurry.completes, 4 blurry.incompletes, 11 hairs, 3.9ms\n",
      "image 128/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P102_g97_6.jpg: 480x640 12 completes, 19 blurry.completes, 18 hairs, 3.5ms\n",
      "image 129/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P106_g105_1.jpg: 480x640 3 completes, 19 blurry.completes, 2 blurry.incompletes, 15 hairs, 3.4ms\n",
      "image 130/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P106_g105_6.jpg: 480x640 7 completes, 18 blurry.completes, 11 hairs, 3.4ms\n",
      "image 131/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P108_g67_1.jpg: 480x640 9 completes, 5 blurry.completes, 12 hairs, 3.9ms\n",
      "image 132/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P108_g67_6.jpg: 480x640 16 completes, 5 blurry.completes, 13 hairs, 4.0ms\n",
      "image 133/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P109_g50_4.jpg: 480x640 9 completes, 1 incomplete, 15 blurry.completes, 2 blurry.incompletes, 33 hairs, 3.7ms\n",
      "image 134/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P109_g50_7.jpg: 480x640 18 completes, 17 blurry.completes, 2 blurry.incompletes, 15 hairs, 3.7ms\n",
      "image 135/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P112_g103_2.jpg: 480x640 8 completes, 8 blurry.completes, 6 hairs, 3.8ms\n",
      "image 136/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P112_g103_8.jpg: 480x640 29 completes, 11 blurry.completes, 15 hairs, 3.4ms\n",
      "image 137/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P115_g55_3.jpg: 480x640 18 completes, 8 blurry.completes, 31 hairs, 3.6ms\n",
      "image 138/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P115_g55_6.jpg: 480x640 29 completes, 1 incomplete, 16 hairs, 4.2ms\n",
      "image 139/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P121_g29_1.jpg: 480x640 11 completes, 4 blurry.completes, 35 hairs, 3.4ms\n",
      "image 140/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P121_g29_7.jpg: 480x640 19 completes, 8 blurry.completes, 29 hairs, 3.4ms\n",
      "image 141/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P122_g13_4.jpg: 480x640 7 completes, 2 blurry.completes, 28 hairs, 3.4ms\n",
      "image 142/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P122_g13_5.jpg: 480x640 17 completes, 1 incomplete, 7 blurry.completes, 3 hairs, 3.6ms\n",
      "image 143/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P125_g83_2.jpg: 480x640 8 completes, 7 blurry.completes, 1 hair, 3.4ms\n",
      "image 144/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P125_g83_6.jpg: 480x640 13 completes, 8 blurry.completes, 1 blurry.incomplete, 5 hairs, 3.4ms\n",
      "image 145/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P126_g31_1.jpg: 480x640 9 completes, 6 blurry.completes, 26 hairs, 4.1ms\n",
      "image 146/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P126_g31_5.jpg: 480x640 17 completes, 8 blurry.completes, 8 hairs, 3.6ms\n",
      "image 147/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P127_g35_3.jpg: 480x640 22 completes, 4 blurry.completes, 17 hairs, 3.4ms\n",
      "image 148/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P127_g35_6.jpg: 480x640 21 completes, 1 incomplete, 7 blurry.completes, 3 blurry.incompletes, 5 hairs, 3.4ms\n",
      "image 149/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P128_g88_3.jpg: 480x640 11 completes, 4 blurry.completes, 31 hairs, 3.4ms\n",
      "image 150/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P128_g88_5.jpg: 480x640 9 completes, 11 blurry.completes, 3 hairs, 3.7ms\n",
      "image 151/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P129_g48_2.jpg: 480x640 5 completes, 3 blurry.completes, 6 hairs, 3.5ms\n",
      "image 152/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P129_g48_5.jpg: 480x640 15 completes, 5 blurry.completes, 2 blurry.incompletes, 2 hairs, 3.6ms\n",
      "image 153/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P130_g87_2.jpg: 480x640 23 completes, 1 blurry.complete, 36 hairs, 3.6ms\n",
      "image 154/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P130_g87_5.jpg: 480x640 22 completes, 12 blurry.completes, 3 blurry.incompletes, 11 hairs, 4.0ms\n",
      "image 155/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P131_g100_1.jpg: 480x640 2 completes, 5 blurry.completes, 15 hairs, 4.3ms\n",
      "image 156/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P131_g100_7.jpg: 480x640 13 completes, 28 blurry.completes, 12 hairs, 3.4ms\n",
      "image 157/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P132_g54_1.jpg: 480x640 11 completes, 10 blurry.completes, 6 hairs, 3.4ms\n",
      "image 158/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W1_GC1_R2_P132_g54_8.jpg: 480x640 21 completes, 19 blurry.completes, 3 blurry.incompletes, 15 hairs, 3.5ms\n",
      "image 159/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P13_g126_1.jpg: 480x640 8 completes, 3 blurry.completes, 16 hairs, 3.4ms\n",
      "image 160/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P13_g126_5.jpg: 480x640 21 completes, 5 blurry.completes, 7 hairs, 3.6ms\n",
      "image 161/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P18_g194_2.jpg: 480x640 17 completes, 1 blurry.complete, 10 hairs, 3.4ms\n",
      "image 162/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P18_g194_7.jpg: 480x640 9 completes, 22 blurry.completes, 6 hairs, 3.4ms\n",
      "image 163/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P19_g193_4.jpg: 480x640 26 completes, 1 blurry.complete, 7 hairs, 3.7ms\n",
      "image 164/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P19_g193_5.jpg: 480x640 17 completes, 17 blurry.completes, 8 hairs, 3.4ms\n",
      "image 165/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P22_g173_4.jpg: 480x640 6 completes, 2 blurry.completes, 21 hairs, 3.7ms\n",
      "image 166/166 /home/ray/Downloads/Stomata/T22+T32/T22L600_W3_GC1_R1_P22_g173_7.jpg: 480x640 3 completes, 21 blurry.completes, 21 hairs, 3.4ms\n",
      "Speed: 1.5ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1m/home/ray/runs/detect/predict3\u001b[0m\n",
      "166 labels saved to /home/ray/runs/detect/predict3/labels\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"/home/ray/runs/detect/T22+T32Train/weights/best.pt\")  # load a custom model\n",
    "\n",
    "# Predict with the model\n",
    "results = model.predict( '/home/ray/Downloads/Stomata/T22+T32',save=True,save_crop = False,save_txt = True,save_conf = True)  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis Yolov8n  and Groundtruth predict  \n",
    "\n",
    "Compare all classes count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complete</td>\n",
       "      <td>2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incomplete</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blurry.complete</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blurry.incomplete</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hair</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               class  count\n",
       "0           complete   2044\n",
       "1         incomplete      7\n",
       "2    blurry.complete   1173\n",
       "3  blurry.incomplete     19\n",
       "4               hair   2809"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class_name_to_id_mapping = {\"complete\": 0,\n",
    "                \"incomplete\": 1,\n",
    "                           \"blurry.complete\": 2,\n",
    "                           \"blurry.incomplete\" :3 , \n",
    "                           \"hair\":4\n",
    "                           } # human hair\n",
    "\n",
    "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
    "\n",
    "#get predicts data\n",
    "predicts = [os.path.join('/home/ray/runs/detect/predict2/labels', x) for x in os.listdir('/home/ray/runs/detect/predict2/labels') if x[-3:] == 'txt' ]\n",
    "\n",
    "\n",
    "def GetPredictResults(predicts,dic):\n",
    "\n",
    "    \n",
    "    for i in range(0,len(predicts)):\n",
    "        predict_file = predicts[i]\n",
    "        with open(predict_file, \"r\") as file:\n",
    "                predict_list = file.read().split(\"\\n\")[:-1]\n",
    "                predict_list = [x.split(\" \") for x in predict_list]\n",
    "                predict_list = [[float(y) for y in x ] for x in predict_list]\n",
    "\n",
    "        \n",
    "        predict_list = np.array(predict_list)\n",
    "    \n",
    "\n",
    "        for ann in predict_list:\n",
    "            obj_cls, x0, y0, x1, y1 , conf = ann\n",
    "            dic[\"count\"][int(obj_cls)] += 1\n",
    "        \n",
    "        \n",
    "\n",
    "dic = { \"class\" : class_name_to_id_mapping.keys() , \"count\" : [0,0,0,0,0]}\n",
    "\n",
    "GetPredictResults(predicts,dic)\n",
    "\n",
    "dic_df = pd.DataFrame(dic)\n",
    "\n",
    "dic_df.to_csv('T32PredictResults.csv')\n",
    "\n",
    "dic_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StomataYolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
